{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import mechanicalsoup\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the session\n",
    "session = requests.Session()\n",
    "\n",
    "# Create the payload\n",
    "payload = {'login_user_email':'zhouxing@uchicago.edu', \n",
    "          'login_user_password':'Xz19980114!'\n",
    "         }\n",
    "\n",
    "# Post the payload to the site to log in\n",
    "s = session.post(\"https://seekingalpha.com/account/login\", data=payload)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mechanize\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/08/77368b47ba2f9e0c03f33902ed2c8e0fa83d15d81dcf7fe102b40778d810/mechanize-0.4.5-py2.py3-none-any.whl (109kB)\n",
      "\u001b[K     |████████████████████████████████| 112kB 1.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: html5lib>=0.999999999 in /Users/zhou/anaconda3/lib/python3.7/site-packages (from mechanize) (1.0.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/zhou/anaconda3/lib/python3.7/site-packages (from html5lib>=0.999999999->mechanize) (1.12.0)\n",
      "Requirement already satisfied: webencodings in /Users/zhou/anaconda3/lib/python3.7/site-packages (from html5lib>=0.999999999->mechanize) (0.5.1)\n",
      "Installing collected packages: mechanize\n",
      "Successfully installed mechanize-0.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install mechanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import mechanicalsoup\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mechanicalsoup.form.Form at 0x11645aef0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "br = mechanicalsoup.StatefulBrowser(\n",
    "    soup_config={'features': 'lxml'},\n",
    "    raise_on_404=True,\n",
    "    user_agent='MyBot/0.1: mysite.example.com/bot_info',\n",
    ")\n",
    "\n",
    "br.open(\"https://seekingalpha.com/account/login\")\n",
    "br.select_form('#orthodox_login')\n",
    "\n",
    "\n",
    "# browser[\"login\"] = args.username\n",
    "# browser[\"password\"] = args.password\n",
    "# resp = browser.submit_selected()\n",
    "\n",
    "\n",
    "submit = br.get_current_page().find('input', id='button3')\n",
    "form = br.select_form()\n",
    "form.choose_submit(submit)\n",
    "br.submit_selected()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the next page and scrape the data\n",
    "s = session.get('https://seekingalpha.com/article/1594412-siemens-aktiengesellschaft-management-discusses-q3-2013-results-earnings-call-transcript')\n",
    "\n",
    "soup = BeautifulSoup(s.text, 'html.parser')\n",
    "soup.find(\"div\", {\"id\": \"a-body\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the url and read\n",
    "def getHtml(url):\n",
    "    page = urllib.request.urlopen(url)\n",
    "    html = page.read()\n",
    "    page.close()\n",
    "    #print(html)\n",
    "    return html\n",
    "# compile the regular expressions and find all stuff we need\n",
    "def getUrl(html,reg):\n",
    "    '''\n",
    "    return address of pdf\n",
    "    reg = r'href=\"(.*?.pdf)\">(.*?\\(PDF\\))'\n",
    "    '''\n",
    "    html = html.decode('utf-8')\n",
    "    url_lst = re.findall(reg,html)\n",
    "    #print(url_lst)\n",
    "    return url_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
